<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tietoprovinssi Voice-Image-Edit</title>

    <link href="https://fonts.googleapis.com/css2?family=Exo:wght@400;500;600;700&display=swap" rel="stylesheet" />
    <!-- frontend backend communication -->
    <script src="https://cdn.socket.io/4.1.2/socket.io.min.js"></script>
    <!-- ort is required by vad -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.js"></script>
    <!-- vad for audio recording -->
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad/dist/index.browser.js"></script>
    <style>
      body {
        font-family: sans-serif;
        font-family: "Exo", sans-serif;
        background: #070815;
        color: white;
      }
      h1 {
        text-align: center;
        font-weight: lighter;
      }
      h2 {
        text-align: center;
        font-weight: lighter;
      }
      h3 {
        text-align: center;
        font-weight: lighter;
      }
      .p-text {
        font-size: 1.2rem;
        color: white;
        font-family: "Exo", sans-serif;
      }
      .flex-center {
        display: flex;
        align-items: center;
        justify-content: center;
      }
      .flex-horizontal {
        display: flex;
        align-items: center;
      }
    </style>
  </head>
  <body>
    <h1>Tietoprovinssi Demo - Voice Guided AI Image Editing</h1>
    <h2>GPT Lab Sein√§joki</h2>
    <div class="flex-center">
      <p>Status:&nbsp;</p>
      <p id="general_status">Waiting...</p>
    </div>
    <div class="flex-center">
      <input type="radio" id="rb_auto" name="rb_lang" checked="true" />
      <label for="rb_auto">Auto</label>
      <input type="radio" id="rb_en" name="rb_lang" />
      <label for="rb_en">English</label>
      <input type="radio" id="rb_fi" name="rb_lang" />
      <label for="rb_fi">Finnish</label>
    </div>
    <div class="flex-center">
      <label> <input type="checkbox" id="toggleRecording" /> Toggle recording:&nbsp;</label>
      <p style="color: lightcoral" id="recording_status">Disabled</p>
    </div>
    <div>
      <div class="flex-horizontal">
        <p class="p-text">Transcription:&nbsp;</p>
        <p class="p-text" id="transcription"></p>
      </div>
      <div class="flex-horizontal">
        <p class="p-text">Translation:&nbsp;</p>
        <p class="p-text" id="translation"></p>
      </div>
    </div>
    <div class="flex-center">
      <img id="generated_image" style="display: none; max-width: 100%" />
    </div>

    <script>
      const transcription = document.getElementById("transcription");
      const translation = document.getElementById("translation");
      const general_status = document.getElementById("general_status");
      const recording_status = document.getElementById("recording_status");
      const toggleRecording = document.getElementById("toggleRecording");
      const generated_image = document.getElementById("generated_image");

      const rb_auto = document.getElementById("rb_auto");
      const rb_en = document.getElementById("rb_en");
      const rb_fi = document.getElementById("rb_fi");

      let recordingEnabled = false;
      let backendProcessing = false;
      let shouldClearTranscription = false;
      let speechTimer;
      let lastSpeechEndTime = 0;
      let myvad = null;
      let socket = null;

      toggleRecording.addEventListener("change", () => {
        recordingEnabled = toggleRecording.checked;
        updateRecordingStatusStyle();
      });

      async function startMicVAD(stream) {
        myvad = await vad.MicVAD.new({
          stream,
          positiveSpeechThreshold: 0.8,
          negativeSpeechThreshold: 0.8 - 0.15,
          minSpeechFrames: 1,
          preSpeechPadFrames: 1,
          redemptionFrames: 2,
          onSpeechStart: () => {
            if (!recordingEnabled || backendProcessing) {
              return;
            }
            if (shouldClearTranscription) {
              transcription.innerText = "";
              shouldClearTranscription = false;
            }
            console.log("Speech start");
            general_status.innerText = "Listening...";
            clearTimeout(speechTimer);
          },
          onSpeechEnd: (audio) => {
            if (!recordingEnabled || backendProcessing) {
              return;
            }
            console.log("Speech end");
            const wavBuffer = vad.utils.encodeWAV(audio);
            const base64 = vad.utils.arrayBufferToBase64(wavBuffer);
            general_status.innerText = "Processing...";
            if (socket && socket.connected) {
              socket.emit("audio_data", base64);
            }
            lastSpeechEndTime = Date.now();
            speechTimer = setTimeout(() => {
              if (Date.now() - lastSpeechEndTime >= 3000) {
                general_status.innerText = "Translating...";
                if (socket && socket.connected) {
                  socket.emit("translate");
                }
                backendProcessing = true;
                updateRecordingStatusStyle();
              }
            }, 3000);
          },
        });
        myvad.start();
      }

      async function main() {
        updateRecordingStatusStyle();
        socket = io("http://localhost:5001");

        socket.on("connect", () => {
          console.log("Connected to server");
        });

        socket.on("transcription", (data) => {
          general_status.innerText = "Transcription received";
          transcription.innerText = (transcription.innerText + data).replace(".", " ").replace("  ", " ");
        });

        socket.on("translation", async (data) => {
          general_status.innerText = "Translation received";
          translation.innerText = data;
          await processCommand(data);
        });

        socket.on("status", async (data) => {
          console.log("Status: " + data);
          general_status.innerText = data;
        });

        socket.on("disconnect", () => {
          console.log("Disconnected from server");
        });

        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: false,
            autoGainControl: false,
            noiseCancellation: false,
          },
          video: false,
        });
        await startMicVAD(stream);

        rb_auto.addEventListener("change", () => {
          if (socket && socket.connected) {
            socket.emit("lang_select", "");
          }
        });

        rb_en.addEventListener("change", () => {
          if (socket && socket.connected) {
            socket.emit("lang_select", "en");
          }
        });

        rb_fi.addEventListener("change", () => {
          if (socket && socket.connected) {
            socket.emit("lang_select", "fi");
          }
        });
      }
      main();

      async function processCommand(command) {
        backendProcessing = true;
        updateRecordingStatusStyle();
        general_status.innerText = "Processing command...";
        const response = await fetch("/process_command", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify({ command }),
        });
        if (response.headers.get("content-type") === "application/json") {
          general_status.innerText = "Error: " + (await response.json()).error;
          backendProcessing = false;
          updateRecordingStatusStyle();
          return;
        }
        const blob = await response.blob();
        const url = URL.createObjectURL(blob);
        generated_image.src = url;
        generated_image.style.display = "block";
        backendProcessing = false;
        shouldClearTranscription = true;
        updateRecordingStatusStyle();
        general_status.innerText = "Done! Waiting for input...";
      }

      function updateRecordingStatusStyle() {
        let status = "Unknown";
        recording_status.style = "";
        if (backendProcessing) {
          status = "Processing";
        } else if (recordingEnabled) {
          status = "Enabled";
        } else {
          status = "Disabled";
        }
        recording_status.innerText = status;
        if (status === "Enabled") {
          recording_status.style.color = "lightgreen";
        } else if (status === "Disabled") {
          recording_status.style.color = "lightcoral";
        } else {
          recording_status.style.color = "yellow";
        }
      }
    </script>
  </body>
</html>
